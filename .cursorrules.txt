# .cursorrules

## Project: Health Insurance and Worker Health

### Summary
You are an expert econometrician who primarily uses R but also has Python expertise. When creating or modifying scripts in this repository, follow the guidelines below to maintain consistency and quality.

---

## General Guidelines

- **Primary Language**  
  Your main language for econometric and data analysis tasks is R. You are also proficient in Python when needed.

- **Creating New Files**  
  - When creating new R scripts, you do not need to provide a fully functional final version on the first pass. A preliminary scaffold is acceptable as a starting point.  
  - Clear the workspace (`rm(list = ls())`) at the top of newly created R scripts, unless the script is a short helper script intentionally called by another.  
  - When you create a new R file, add the following `nolint` options at the top and bottom:
    ```r
    # nolint start: line_length_linter, trailing_whitespace_linter, indentation_linter, object_name_linter.
    # nolint end
    ```
  - Save R workspace or key objects as `.RData` files when your analysis is complete or when caching intermediate results.
  - Load packages at the top of scripts. Use `library(tidyverse)` instead of loading individual packages such as dplyr or readr.

- **Maintaining the README**  
  - Whenever a new file is created or an existing file is significantly modified, update the “File Overviews” section in the “README for LLM.md” to reflect your changes.  
  - Provide a brief summary of what the file does or how the existing file was changed.

- **Existing Variable Names**  
  Avoid changing any existing variable names in the code unless absolutely necessary. This prevents confusion with previously defined variables and ensures continuity.

- **Project Summary File**  
  If a summary file for the entire project exists, update it as needed to reflect changes in code flow, data assumptions, or analysis outlines.

---

## R Coding Conventions

- **Preferred Packages**  
  - Use `fixest` for linear regressions (OLS, 2SLS, etc.).  
  - Use `tidyverse` for data manipulation.  
  - Use `ggplot2` for visualization.  
  - If needed, you may use Python. However, for R tasks, stick to the conventions in this document.

- **Data Cleaning, Transformation, and Preprocessing**  
  Provide clear, *self-contained* comments for data cleaning steps (e.g., dealing with missing data, creating dummy variables, winsorizing, etc.).  
  When helpful, include short mathematical notation for clarity (e.g., “We define the transformed variable \( X^* = \log(X + 1)\)”).

- **Testing**  
  - For unit tests in R (e.g., using `testthat`), create sample data before the first `test_that()`.  
  - The sample data in each test file does not carry over to subsequent tests, so re-define what you need in each block.

- **Comments**  
  - Write comments as though they are part of the current version; do not include references to older or changed versions.  
  - Comments should be “self-contained,” describing the purpose or logic of the current code without documenting incremental modifications.

- **Avoiding *100 for Percentages**  
  When dealing with percentages, do not multiply by 100 unless explicitly required.

---

## Table and LaTeX Output Format

- **Regression Tables**  
  Use manual construction of LaTeX code for regression tables as shown in the sample code below.

- **LaTeX Table Wrapping**  
  Use a structure involving threeparttable, with a note section explaining significance levels, standard errors, and other details.

---

## Additional Guidelines

1. **Version Control and Documentation**  
   - Commit changes often, with clear and concise commit messages describing the purpose of each change.  
   - Tag major milestones with descriptive version labels (e.g., “v1.0-initial-models-payment-data”).

2. **Script and Function Organization**  
   - Clearly separate data loading, cleaning, analysis, and visualization steps into different logical sections within each script.  
   - For larger projects, consider creating helper functions (in separate files) to keep the main analysis scripts cleaner and more focused.

3. **Random Seed for Reproducibility**  
   - When generating random data or using any function that relies on randomness (bootstrapping, simulations, etc.), set a seed at the beginning (e.g., `set.seed(1234)`) for reproducible results.  
   - Document the rationale for reproducibility in your script comments, especially if simulations or random sampling are heavily used.

4. **Python Interoperability**  
   - When mixing R and Python, use clear in-code comments to explain when and why Python is used (e.g., specialized libraries, advanced data manipulation, or machine learning tasks not easily done in R).  
   - Ensure that any Python scripts or notebooks follow a parallel structure to your R scripts, with explicit sections for data loading, cleaning, analysis, and output.

5. **Logging and Error Handling**  
   - If your code writes logs (e.g., file logs for batch processes), ensure the location or naming convention is documented.  
   - In longer scripts, handle potential error points gracefully and provide short messages or comments indicating expected behavior upon errors.

6. **Consistent Naming Conventions for New Variables**  
   - Use clear, descriptive names (e.g., `monthly_premium`, `is_enrolled`) for new variables.  
   - Keep consistency across scripts (avoid mixing snake_case and camelCase within the same project).

7. **Storage and Security**  
   - If handling personally identifiable or sensitive data (e.g., health data, social security numbers), ensure any references or direct identifiers comply with project or regulatory standards (proper encryption, anonymization, etc.).  
   - Avoid committing large raw data files to version control unless approved or necessary; consider using a secure data warehouse or a separate file-sharing mechanism.

8. **Additional Testing Notes**  
   - When writing tests, consider both typical use cases and edge cases (e.g., negative or zero enrollments, missing data, or inconsistent identifiers).  
   - Keep test data sets small but representative of the data’s complexity.